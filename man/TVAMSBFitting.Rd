% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/TVAMSBFitting.R
\name{TVAMSBFitting}
\alias{TVAMSBFitting}
\title{Iterative Smooth Backfitting Algorithm}
\usage{
TVAMSBFitting(Y, t, x, T, X, h0 = NULL, h = NULL, K = "epan",
  supp0 = NULL, supp = NULL)
}
\arguments{
\item{Y}{An \emph{n}-dimensional list whose elements consist of vectors of longitudinal responses.}

\item{t}{An \emph{M} vector of estimation time points for marginal mean curve of \emph{Y(t)}.}

\item{x}{An \emph{N} by \emph{d} matrix whose column vectors consist of \emph{N} vectors of estimation points for each component surface.}

\item{T}{An \emph{n}-dimensional list whose elements consist of vectors of time points corresponding to longitudinal responses \emph{Y}.}

\item{X}{An \emph{n} by \emph{d} matrix whose row vectors consist of multivariate predictors.}

\item{h0}{A scalar value of bandwidth for kernel smoothing to estimate marginal mean curve of \emph{Y(t)}.}

\item{h}{A \emph{d} vector of bandwidths for kernel smoothing to estimate each component surface.}

\item{K}{A \code{function} object representing the kernel to be used in the smooth backfitting (default is 'epan', the the Epanechnikov kernel.).}

\item{supp0}{A 2 vector whose elements consist of the lower and upper limit of estimation interval for marginal mean curve (default is the \emph{1}-dimensional unit interval, \emph{[0,1]}).}

\item{supp}{A \emph{d} by 2 matrix whose row vectors consist of the lower and upper limits of estimation intervals for each component function (default is the \emph{d}-dimensional unit rentangle of \emph{[0,1]^d}).}
}
\value{
A list containing the following fields:
\item{SBFit}{An \emph{N} by \emph{N} by \emph{d} array whose elements consist of the locally linear smooth backfitting component surface estimators at the given estimation points.}
\item{f0}{An \emph{M} vector whose elements consist of marginal mean curve of \emph{Y(t)}.}
\item{fj}{An \emph{N} by \emph{N} by \emph{d} array whose elements consist of the locally linear kernel smoothing estimators of marginal component surface.}
\item{itemNum}{The iteration number that the smooth backfitting algorithm has stopped.}
\item{itemErr}{The iteration error of the smooth backfitting algorithm that represents the maximum L2 distance among component functions in the last successive updates.}
}
\description{
Smooth backfitting procedure for nonparametric time-varying additive models
}
\details{
\code{TVAMSBFitting} fits component surface of time-varying additive models for a longitudinal response and a multivariate predictor based on the smooth backfitting algorithm proposed by Mammen et al. (1999) and intensively studied by Mammen and Park (2006), Yu et al. (2008), Lee et al. (2010, 2012) and so on. \code{TVAMSBFitting} only focuses on the local linear smooth backfitting estimator with multivariate predictor case for the purpose of enjoying smooth surface estimation. Support of the multivariate predictor is assumed to be a product of closed intervals. Especially in this development, one can designate an estimation support of additive models when the additive modeling is only allowed over restricted intervals or one is interested in the modeling over the support (see Han et al., 2016). If one puts \code{X} on the argument of estimation points \code{x}, \code{TVAMSBFitting} returns estimated values of conditional mean curve for responses given observed predictors.
}
\examples{
set.seed(100)

n <- 200
N <- 51
M <- 81
d <- 2

nSet <- sample(50:100,n,replace=TRUE)
T <- list()
for (i in 1:n){
  T[[i]] <- runif(nSet[i],0,1)
}

X <- pnorm(matrix(rnorm(n*d),nrow=n,ncol=d)\%*\%matrix(c(1,0.5,0.5,1),nrow=2,ncol=2))

g1 <- function(x1) 2*(x1-0.5)
g2 <- function(x2) sin(2*pi*x2)

g <- function(u,x) sin(2*pi*u)*g1(x[1]) + cos(2*pi*u)*g2(x[2])

Y <- list()
for (i in 1:n){
  tmpY <- c()
  for (j in 1:nSet[i]){
    tmpY[j] <- g(T[[i]][j],X[i,])
  }
  Y[[i]] <- tmpY+rnorm(nSet[i],0,0.2)
}

t <- seq(0,1,length.out=M)
x <- matrix(rep(seq(0,1,length.out=N),d),nrow=N,ncol=d)

h0 <- 0.15
h <- c(0.15,0.15)

sbfLLSurf <- TVAMSBFitting(Y,t,x,T,X,h0=h0,h=h)

g1SbfLL <- sbfLLSurf$SBFit[,,1]
g2SbfLL <- sbfLLSurf$SBFit[,,2]

g1Eval <- matrix(nrow=M,ncol=N)
g2Eval <- matrix(nrow=M,ncol=N)
for (i in 1:M) {
  for (j in 1:N) {
    g1Eval[i,j] <- sin(2*pi*t[i])*g1(x[j,1])
    g2Eval[i,j] <- cos(2*pi*t[i])*g2(x[j,2])
  }
}

par(mfrow=c(2,2))
persp(u0,x0,g1Eval,theta=-30,phi=30,lty=2, border=NA, shade=0.5,xlab='t',ylab='x1',zlab='g1Eval')
persp(u0,x0,g2Eval,theta=20,phi=30,lty=2, border=NA, shade=0.5,xlab='t',ylab='x2',zlab='g2Eval')

persp(u0,x0,g1SbfLL,theta=-30,phi=40, lty=2, border=NA, shade=0.5,xlab='t',ylab='x1',zlab='g1Est')
persp(u0,x0,g2SbfLL,theta=20,phi=40, lty=2, border=NA, shade=0.5,xlab='t',ylab='x2',zlab='g2Est')
}
\references{
\cite{Mammen, E., Linton, O. and Nielsen, J. (1999), "The existence and asymptotic properties of a backfitting projection algorithm under weak conditions", Annals of Statistics, Vol.27, No.5, p.1443-1490.}

\cite{Mammen, E. and Park, B. U. (2006), "A simple smooth backfitting method for additive models", Annals of Statistics, Vol.34, No.5, p.2252-2271.}

\cite{Yu, K., Park, B. U. and Mammen, E. (2008), "Smooth backfitting in generalized additive models", Annals of Statistics, Vol.36, No.1, p.228-260.}

\cite{Lee, Y. K., Mammen, E. and Park., B. U. (2010), "backfitting and smooth backfitting for additive quantile models", Vol.38, No.5, p.2857-2883.}

\cite{Lee, Y. K., Mammen, E. and Park., B. U. (2012), "Flexible generalized varying coefficient regression models", Annals of Statistics, Vol.40, No.3, p.1906-1933.}

\cite{Han, K., Mueller, H.-G. and Park, B. U. (2016), "Smooth backfitting for additive modeling with small errors-in-variables, with an application to additive functional regression for multiple predictor functions", Bernoulli (accepted).}

\cite{Zhang, X., Park, B. U. and Wang, J.-L. (2013), "Time-varying additive models for longitudinal data", Journal of the American Statistical Association, Vol.109, No.503, p.983-998.}
}
